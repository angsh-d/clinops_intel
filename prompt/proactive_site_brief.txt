You are synthesizing a Site Intelligence Brief for site {site_id} from proactive scan findings.

ORGANIZATIONAL CONTEXT:
This is a CRO-managed multi-site clinical trial. CRAs are CRO employees. Monitoring gaps, missed visits, and CRA transitions are CRO operational issues. The Sponsor sets protocol design and enrollment targets but does not conduct day-to-day site oversight.

FINDINGS BY AGENT ({findings_count} total findings):
{findings_by_agent}

ACTUAL TOOLS CALLED DURING INVESTIGATION (use ONLY these tool names in data_source citations):
{investigation_tools}

INSTRUCTIONS:
Analyze all findings for this site and produce a structured intelligence brief. Cross-reference findings across agents to identify shared root causes. When multiple agents flag the same site, there is likely a shared operational root cause.

Produce a JSON response with these 5 sections:

{{
  "risk_summary": {{
    "overall_risk": "low / moderate / high / critical",
    "headline": "One sentence summarizing the site's current risk posture",
    "key_risks": [
      {{
        "risk": "Specific risk description",
        "severity": "low / moderate / high / critical",
        "source_agents": ["agent_ids that flagged this"],
        "evidence": "Specific data points supporting this risk",
        "causal_chain_explained": [
          {{ 
            "step": "Step 1 Title", 
            "explanation": "Plain English explanation of what happened first",
            "data_source": {{ "tool": "tool_name_that_provided_this_data", "metric": "specific_metric_or_value", "row_count": 123 }}
          }},
          {{ 
            "step": "Step 2 Title", 
            "explanation": "Plain English explanation of what happened next",
            "data_source": {{ "tool": "tool_name", "metric": "specific_metric_or_value", "row_count": 45 }}
          }},
          {{ 
            "step": "Outcome", 
            "explanation": "Plain English explanation of the final observable problem",
            "data_source": {{ "tool": "tool_name or 'inference'", "metric": "metric or 'derived from above'", "row_count": 0 }}
          }}
        ]
      }}
    ]
  }},
  "vendor_accountability": {{
    "cro_issues": ["List of CRO-attributable operational issues (CRA staffing, monitoring, query management)"],
    "site_issues": ["List of site-attributable issues (PI engagement, patient recruitment, staff training)"],
    "sponsor_considerations": ["List of sponsor-level items (protocol design, enrollment targets, regulatory)"]
  }},
  "cross_domain_correlations": [
    {{
      "finding": "One sentence describing the cross-domain correlation",
      "agents_involved": ["agent_id_1", "agent_id_2"],
      "causal_chain": "root_cause → mechanism → observed_effect",
      "confidence": 0.0-1.0
    }}
  ],
  "recommended_actions": [
    {{
      "priority": 1,
      "action": "Specific actionable step",
      "rationale": "Why this action matters",
      "urgency": "immediate / this_week / this_month",
      "owner": "CRO Clinical Operations Lead / CRO CRA Manager / Sponsor Medical Monitor / etc."
    }}
  ],
  "trend_indicator": "improving / stable / deteriorating"
}}

IMPORTANT:
- Use plain, direct language — no jargon
- Every risk must cite specific evidence from the findings
- Recommended actions must be realistic clinical operations steps a CRO can execute
- trend_indicator reflects whether the site's overall operational health is improving, stable, or deteriorating based on the findings
- causal_chain_explained MUST be in plain English that a non-technical person can understand
- ALWAYS include temporal details (dates, timeframes, durations) in each step when available from the findings

DATA GROUNDING REQUIREMENT (CRITICAL):
- Each causal chain step MUST include a data_source object citing the specific tool and metric that supports the claim
- You MUST ONLY use tool names from the "ACTUAL TOOLS CALLED" list above - DO NOT invent or guess tool names
- If the tool you need wasn't called, use tool: "inference" and explain what evidence you're deriving from
- If a step is a logical inference (not directly from data), set tool to "inference" and explain in metric what it's derived from
- NEVER claim data exists if the tool returned 0 rows - be honest about data gaps
- Match row_count to the actual row counts shown in the tools list
- If you cannot cite a specific data source for a claim, DO NOT include that claim

Example with data citations:
  [
    {{ 
      "step": "Staffing Gap (July 2024)", 
      "explanation": "The CRA assigned to this site left on July 15th and wasn't replaced until August 28th - a 6-week gap.",
      "data_source": {{ "tool": "cra_assignment_history", "metric": "gap_days=44, transition from CRA-001 to CRA-002", "row_count": 3 }}
    }},
    {{ 
      "step": "Missed Visits (Aug 2024)", 
      "explanation": "During the staffing gap, three scheduled monitoring visits on Aug 5, 12, and 19 were skipped.",
      "data_source": {{ "tool": "monitoring_visit_history", "metric": "3 visits with status=skipped in date range", "row_count": 3 }}
    }},
    {{ 
      "step": "Query Backlog (Current)", 
      "explanation": "As of today, 45 queries remain open, with the oldest dating back 30+ days to late July.",
      "data_source": {{ "tool": "query_burden", "metric": "open_queries=45, max_age_days=30", "row_count": 45 }}
    }}
  ]